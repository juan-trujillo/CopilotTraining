---
status: active
updated: 2026-02-12
section: "Agent Architecture"
references:
  - url: https://code.visualstudio.com/docs/copilot/customization/custom-agents
    label: "Custom agents in VS Code"
    verified: 2026-02-12
  - url: https://code.visualstudio.com/docs/copilot/agents/subagents
    label: "Subagent invocation and parallel execution"
    verified: 2026-02-12
  - url: https://code.visualstudio.com/updates/v1_109#_agent-orchestration
    label: "VS Code v1.109 agent orchestration features"
    verified: 2026-02-12
  - url: https://github.com/bradygaster/squad
    label: "Squad â€” production-ready agent team system"
    verified: 2026-02-12
---

# Agent Teams: Coordinating Specialized AI Roles for Complex Development

> **The Question This Talk Answers:**
> *"How do I coordinate multiple specialized agents to handle complex development tasks that exceed single-agent capacity?"*

**Duration:** 45 minutes | **Target Audience:** Developers / Architects / Engineering Managers

---

## ğŸ“Š Content Fitness

| Criterion | Assessment | Notes |
|-----------|-----------|-------|
| **Relevant** | ğŸŸ¢ High | Complex development tasks require specializationâ€”team patterns enable coordination without context pollution |
| **Compelling** | ğŸŸ¢ High | Production-ready system ([Squad](https://github.com/bradygaster/squad)) available today; persistent AI teams you can deploy in < 10 minutes |
| **Actionable** | ğŸŸ¢ High | `npx github:bradygaster/squad` gives you a full team immediately; agents learn your codebase and compound knowledge over time |

**Overall Status:** ğŸŸ¢ Ready to use

---

## ğŸ“½ï¸ Slide Generation Mapping

### Slide Sequence (Generated Automatically)

1. **Title/Logo Slide** â† H1 title + subtitle
2. **Question/Objective Slide** â† "The Question This Talk Answers"
3. **Table of Contents Slide** â† Auto-generated from ğŸ¬ sections
4. **Problem Slide** â† "The Problem"
5. **Solution Overview** â† "The Solution"
6. **Key Artifacts** â† "Key Artifacts" inventory
7. **Mental Model Shift** â† Move-Toward/Away/Against
8. **When to Use Decision Tree** â† "When to Use This Pattern"
9. **Core Architecture** â† ğŸ¬ Section 1 (2-3 slides)
10. **Squad: Production-Ready Agent Teams** â† ğŸ¬ Section 2 (3-4 slides)
11. **Getting Started with Squad** â† ğŸ¬ Section 3 (4-5 slides)
12. **Orchestration Patterns** â† ğŸ¬ Section 4 (3-4 slides)
13. **Use Cases** â† Real-World Use Cases (1-2 slides)
14. **Actionable Outcomes** â† What You Can Do Today
15. **Related Patterns** â† Related Patterns
16. **Official Documentation** â† ğŸ“š section
17. **End Slide** â† Auto-generated

### Major Sections (TOC Entries)

```markdown
<!-- ğŸ¬ MAJOR SECTION: Core Architecture -->
<!-- ğŸ¬ MAJOR SECTION: Squad: Production-Ready Agent Teams -->
<!-- ğŸ¬ MAJOR SECTION: Getting Started with Squad -->
<!-- ğŸ¬ MAJOR SECTION: Orchestration Patterns -->
```

---

## The Problem

### Key Points

- **Complex tasks exceed single-agent capacity**
  Real development requires planning, implementation, review, testingâ€”different cognitive modes that single agents struggle to balance simultaneously.

- **Context pollution degrades quality**
  One agent juggling planning and coding accumulates 50-80% of its context window on information irrelevant to the current phase, reducing output quality by 30-40%.

- **Tool overload creates confusion**
  An agent with 15+ tools may misuse edit tools during planning phase or research tools during implementation, leading to wasted iterations.

- **No specialization, no expertise**
  General-purpose agents perform at 60-70% effectiveness across all tasks; specialists tuned for one cognitive mode operate at 90-95% effectiveness within their domain.

### Narrative

Single agents hit a ceiling around 300-500 lines of change or 3-4 hours of work. They can plan OR implement wellâ€”rarely both in the same session. As context accumulates, quality degrades: instructions for planning contaminate implementation, implementation details clutter planning sessions, and the agent loses focus.

The traditional solutionâ€”better prompts or smarter modelsâ€”treats the symptom, not the cause. The real issue is cognitive overload. Asking one agent to research, strategize, execute, and validate is like asking a single developer to be architect, coder, QA, and tech writer simultaneously. They'll do each job adequately, but none excellently.

The solution isn't a smarter single agentâ€”it's coordinated specialists. An orchestration layer delegates work, specialists execute within their domains, and the system outperforms any individual agent. This is how human teams work. Now AI teams can work the same way.

---

## The Solution: Multi-Agent Team Orchestration

### What It Does

Agent team orchestration distributes complex development workflows across specialized AI agents, each optimized for a specific cognitive mode (planning, implementation, review, testing). A coordinator agent manages the team, maintaining clean separation between phases while enabling parallel execution of independent tasks.

[Squad](https://github.com/bradygaster/squad) is a production-ready implementation of this pattern. It gives you a persistent AI development team through GitHub Copilotâ€”specialists that live in your repo as files, learn your codebase, share decisions, and compound knowledge across sessions.

### Key Capabilities

- **Role-Based Specialization**: Each agent has a charter defining its identity, expertise, boundaries, and voiceâ€”lead architects, frontend devs, backend devs, and testers each operate within their domain
- **Context Isolation**: Each agent runs in its own context window (6.6% coordinator overhead, 93%+ available for work), preventing information overflow and cross-contamination
- **Parallel Execution**: Independent agents run simultaneouslyâ€”"Team, build the login page" fans out to frontend, backend, tester, and scribe in parallel
- **Persistent Memory**: Agents write learnings to `history.md` after every session, read shared `decisions.md` before every taskâ€”knowledge compounds over time
- **Quality Checkpoints**: Reviewer protocol enforces that rejected work must be revised by a *different* agentâ€”no self-review loops

### Architecture Overview

The coordinator pattern separates "what to do" (orchestration logic) from "how to do it" (specialized execution in worker agents). The coordinator never implements directlyâ€”it routes work based on defined rules, spawns specialists, validates outputs, and aggregates results.

Each agent is intentionally scoped: charters define identity, expertise, boundaries, and voice. Agents read their own `history.md` (personal knowledge) and team `decisions.md` (shared knowledge) before working. This ensures domain focus without cross-contamination.

Agents run in isolated context windows â€” the coordinator uses only 6.6% of its 200K context, leaving 93%+ for coordination. Each spawned agent gets nearly its entire 200K window for the actual task. Fan out to 5 agents and you're working with ~1M tokens of total reasoning capacity.

**Official Documentation:**
- ğŸ“– [Custom Agents in VS Code](https://code.visualstudio.com/docs/copilot/customization/custom-agents) â€” Agent structure, frontmatter configuration, and handoffs
- ğŸ“– [Subagents](https://code.visualstudio.com/docs/copilot/agents/subagents) â€” Subagent invocation, parallel execution, and context isolation
- ğŸ“– [VS Code 1.109 Release Notes](https://code.visualstudio.com/updates/v1_109#_agent-orchestration) â€” Agent orchestration features and invocation controls

---

## ğŸ“¦ Key Artifacts

**This talk references [Squad](https://github.com/bradygaster/squad)**, a complete agent team system that implements all patterns discussed here with persistent, learning agents.

### Primary Artifacts (Squad)

*Shown inline with detailed explanation in the major sections*

- **[`.ai-team/team.md`](#squad-file-structure)** â€” Team roster with roles, capabilities, and project context
- **[`.ai-team/agents/{name}/charter.md`](#squad-agent-charters)** â€” Identity, expertise, boundaries, voice, and model preferences per agent
- **[`.ai-team/agents/{name}/history.md`](#squad-memory-system)** â€” Personal knowledge accumulated across sessions
- **[`.ai-team/routing.md`](#squad-routing)** â€” Work routing table defining who handles what
- **[`.ai-team/decisions.md`](#squad-memory-system)** â€” Shared decision log all agents read before working

### Supporting Files

*Referenced but not shown inline â€” available in the Squad repository*

- **[Squad Repository](https://github.com/bradygaster/squad)** â€” Complete agent team system with persistent memory, parallel execution, GitHub Issues integration, ceremonies, and skills system
- **[Squad Product Guide](https://github.com/bradygaster/squad/blob/main/docs/guide.md)** â€” Comprehensive usage guide covering all features
- **[workshop/06-custom-agents](../../workshop/06-custom-agents/)** â€” Hands-on exercises for building custom agents

---

## ğŸ¯ Mental Model Shift

> **The Core Insight:** From "one smart agent handles everything" to "specialized agents collaborate, each excellent at one thing"

### Move Toward (Embrace These Patterns)

- âœ… **Conductor-Delegate Architecture**: Conductor never implementsâ€”only coordinates specialists who execute in isolated contexts â†’ 70-80% context window savings, cleaner phase separation
- âœ… **Single Responsibility Agents**: Each agent masters one cognitive mode (research/plan/implement/review) â†’ 20-30% quality improvement within each domain
- âœ… **Tool Constraints = Role Enforcement**: Planners have read-only tools; implementers have edit tools; reviewers have analysis tools â†’ Prevents accidental context mixing and tool misuse
- âœ… **Parallel Independent Work**: Launch Explorer + Oracle simultaneously for research; run Security + Performance reviewers in parallel â†’ 3-5x throughput on parallelizable tasks
- âœ… **Structured Handoffs with Approval**: Explicit handoff points with human review gates between planning â†’ implementation â†’ review â†’ commit â†’ Predictable workflow, controlled decision points

### Move Away From (Retire These Habits)

- âš ï¸ **Single Agent for Everything**: Using one agent to research, plan, implement, and review â†’ Context pollution, cognitive overload, 30-40% quality degradation after 300+ LOC
- âš ï¸ **Universal Tool Access**: Giving all agents all tools â†’ Accidental edits during planning, inappropriate research during implementation, wasted iterations
- âš ï¸ **Implicit Phase Transitions**: Moving from planning to implementation without explicit handoff / approval â†’ Scope creep, missed validation, hard to recover from wrong direction

### Move Against (Active Resistance Required)

- ğŸ›‘ **Embedded Instructions in Conductor**: Hardcoding implementation/review logic inside conductor prompts â†’ Makes conductor do specialist work, pollutes context, unmaintainable
- ğŸ›‘ **Sequential When Parallel Possible**: Running Explorer research â†’ Oracle research sequentially when they're independent â†’ 3-5x longer total time, wasted opportunity for parallelism
- ğŸ›‘ **Raw Data Returns from Subagents**: Subagents returning full file contents / raw search results instead of structured findings â†’ Explodes conductor context, defeats isolation benefits

> **Example Transformation:** Before: Single agent with 15 tools spends 80% context on accumulated research/planning notes, outputs mediocre implementation after 4 hours. After: Conductor delegates research to Explorer (isolated context), planning to Planner (fresh context), implementation to Implementer (only plan + files), review to Reviewer (only changes). Each agent operates at 90%+ effectiveness. Total time: 1.5 hours including human approval gates.

---

## When to Use This Pattern

### Decision Tree

```
Q: Does your task exceed single-agent capacity?
â”œâ”€ Simple feature (< 200 LOC, 1-2 files) â†’ Use Plan Mode (single agent)
â”‚  â””â”€ No orchestration needed
â”‚
â”œâ”€ Phased work without role specialization â†’ Use multi-step-tasks pattern
â”‚  â””â”€ Research â†’ Analysis â†’ Implementation phases
â”‚
â”œâ”€ Multiple specialized roles needed â†’ ğŸ‘‰ Use agent-teams (you are here)
â”‚  â””â”€ Examples: Planner + Implementer + Reviewer
â”‚      Security + Performance + Testing
â”‚      Frontend + Backend + Integration
â”‚
â””â”€ Parallel branches + independent features â†’ Use parallel-execution pattern
   â””â”€ Multiple worktrees, concurrent PRs
```

### Use This Pattern When

- Your workflow requires 3+ distinct cognitive modes (research vs. planning vs. coding vs. reviewing)
- Single-agent context window hits 70-80%+ on preparatory work before implementation begins
- You need separation of concerns (prevent planners from implementing, coders from over-planning)
- Quality checkpoints matter (dedicated review agent validates before next phase)
- You're coordinating work across 3+ subsystems that can be researched/implemented in parallel

### Don't Use This Pattern When

- Task is simple (< 200 LOC, 1-2 files) â€” Single agent with Plan Mode is faster, simpler
- Work is linear phases without specialization (research â†’ analysis â†’ implementation) â€” Use multi-step-tasks pattern for simpler orchestration
- You need branch-level parallelism â€” Use parallel-execution for worktree-based concurrency
- Team has < 5 agent-driven tasks/week â€” Coordination overhead exceeds benefits; stick to single agents until volume justifies infrastructure

### Comparison with Related Features

| Aspect | Agent Teams | Multi-Step Tasks | Parallel Execution | Plan Mode |
|--------|-------------|------------------|-------------------|-----------|
| **Best For** | Role-based specialization | Sequential phases | Branch-level concurrency | Simple features |
| **Coordination** | High (conductor required) | Medium (phase handoffs) | Low (independent branches) | None |
| **Context Isolation** | High (subagent contexts) | Medium (phase separation) | High (separate worktrees) | None |
| **Setup Time** | 10 minutes (Squad) | 2-3 hours (phase configs) | 1-2 hours (branch setup) | 0 (built-in) |
| **Throughput** | 3-5x (parallel specialists) | 1.5-2x (phased execution) | 5-10x (branch parallelism) | 1x (baseline) |

---

<!-- ğŸ¬ MAJOR SECTION: Core Architecture -->
## The Team Orchestration Pattern

*How coordinator-delegate architecture enables specialized agents to collaborate without context pollution*

### The Core Architecture

The coordinator pattern separates "what to do" (orchestration logic) from "how to do it" (specialized execution). The coordinator never implements directlyâ€”it receives user requests, routes to specialists based on defined rules, validates outputs, and aggregates results. [Squad](https://github.com/bradygaster/squad) implements this pattern as a complete, production-ready system.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              USER / ENTRY POINT                 â”‚
â”‚     "Team, build user authentication system"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COORDINATOR AGENT                  â”‚
â”‚  â€¢ Routes work via routing table                â”‚
â”‚  â€¢ Spawns specialists (sequential/parallel)     â”‚
â”‚  â€¢ Enforces reviewer protocol                   â”‚
â”‚  â€¢ Selects models per-task (cost-first)         â”‚
â”‚  â€¢ NEVER implements directly                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚           â”‚           â”‚
         â–¼           â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  LEAD   â”‚ â”‚ DEV(S)  â”‚ â”‚ TESTER  â”‚
    â”‚ Agent   â”‚ â”‚ Agents  â”‚ â”‚ Agent   â”‚
    â”‚         â”‚ â”‚         â”‚ â”‚         â”‚
    â”‚ â€¢ Scope â”‚ â”‚ â€¢ Build â”‚ â”‚ â€¢ Test  â”‚
    â”‚ â€¢ Reviewâ”‚ â”‚ â€¢ Code  â”‚ â”‚ â€¢ QA    â”‚
    â”‚ â€¢ Decideâ”‚ â”‚ â€¢ Debug â”‚ â”‚ â€¢ Edge  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      Isolated     Isolated     Isolated
      Context      Context      Context
         â”‚           â”‚           â”‚
         â–¼           â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       ğŸ§  SHARED MEMORY         â”‚
    â”‚  decisions.md + history.md     â”‚
    â”‚  (persistent across sessions)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Design Principles:**

| Principle | Implementation | Benefit |
|-----------|----------------|---------|
| **Single Responsibility** | Each agent masters one cognitive mode | 20-30% quality improvement in that domain |
| **Minimal Tools** | Agents only have tools for their role | Prevents tool misuse, enforces boundaries |
| **Context Isolation** | Subagents run in isolated context windows | 70-80% reduction in main conductor context |
| **Structured Handoffs** | Explicit transitions between phases | Clear approval gates, predictable workflow |
| **Conductor Authority** | Conductor coordinates, never executes | Clean separation of "what" from "how" |

### Why This Works

**Focused Context**: Each agent receives only information relevant to its task. In Squad, each agent loads its charter + history + team decisions â€” nothing from other agents' work. The Lead gets architecture context, the Frontend Dev gets UI context, the Backend Dev gets API context. No agent carries accumulated context from other domains.

**Right Tools, Right Time**: Squad's routing table ensures work goes to the right specialist. The coordinator answers quick questions directly (no agent spawn), routes domain work to specialists, and fans out "Team, ..." requests to all relevant agents in parallel.

**Parallel When Possible**: When you say "Team, build the login page," Squad launches Lead, Frontend, Backend, Tester, and Scribe simultaneously. When agents finish, the coordinator immediately chains follow-up work â€” tests reveal edge cases, the backend agent picks them up. 3-5x throughput on parallelizable work.

**Quality Checkpoints**: Squad's reviewer protocol prevents the common failure mode where an agent keeps "fixing" its own work in circles. On rejection, the original author is locked out â€” a different agent must revise. If that revision is also rejected, a third agent takes over.

**Specialization Advantage**: An agent with a charter tuned for backend development (API design, data modeling, auth patterns) outperforms a generalist by 20-30% within that domain. Same for frontend (UI components, state management) and testing (edge cases, integration patterns). Team of specialists beats single generalist â€” especially when their knowledge compounds over time.

### Tool Assignment Guidelines

| Agent Role | Appropriate Tools | Rationale |
|------------|-------------------|-----------|
| **Research / Discovery** | `search`, `fetch`, `usages`, `githubRepo` | Read-only exploration, no modification risk |
| **Planning / Strategy** | `search`, `fetch`, `create` (plan docs only) | Can document plans, can't implement |
| **Implementation** | `edit`, `create`, `delete`, `search` | Full editing power, focused on execution |
| **Review / Validation** | `search`, `fetch`, `analysis`, `linter` | Read + analyze, can't modify implementation |
| **Testing** | `search`, `create`, `runTests` | Create tests + verify execution |

---

<!-- ğŸ¬ MAJOR SECTION: Squad: Production-Ready Agent Teams -->
## Squad: Production-Ready Agent Teams

*A persistent AI development team that lives in your repo and grows with your code*

### What Is Squad?

**Repository:** [github.com/bradygaster/squad](https://github.com/bradygaster/squad)

Squad gives you an AI development team through GitHub Copilot. Describe what you're building, and Squad proposes a team of specialistsâ€”lead, frontend, backend, testerâ€”that persist as files in your repo. Each agent runs in its own context window, reads its own history and shared team decisions, and writes back what it learned. Knowledge compounds across sessions.

It's not a chatbot wearing hats. Each team member is spawned as a real subagent with its own tools, memory, and area of expertise.

### Squad Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              YOU / ENTRY POINT                   â”‚
â”‚   "Team, build the login page"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SQUAD COORDINATOR                   â”‚
â”‚  â€¢ Routes work based on routing.md              â”‚
â”‚  â€¢ Spawns agents in parallel                    â”‚
â”‚  â€¢ Enforces reviewer protocol                   â”‚
â”‚  â€¢ Selects models per task (cost-first)         â”‚
â”‚  â€¢ NEVER implements directly                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚          â”‚          â”‚          â”‚
     â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ğŸ—ï¸ Lead â”‚ â”‚âš›ï¸ FE   â”‚ â”‚ğŸ”§ BE   â”‚ â”‚ğŸ§ª Test â”‚
â”‚        â”‚ â”‚ Dev    â”‚ â”‚ Dev    â”‚ â”‚ er     â”‚
â”‚ Scope  â”‚ â”‚ UI     â”‚ â”‚ APIs   â”‚ â”‚ Tests  â”‚
â”‚ Review â”‚ â”‚ Comps  â”‚ â”‚ Data   â”‚ â”‚ QA     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Own        Own        Own        Own
  Context    Context    Context    Context
     â”‚          â”‚          â”‚          â”‚
     â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ“‹ SCRIBE (silent)                  â”‚
â”‚  â€¢ Merges decisions from inbox                  â”‚
â”‚  â€¢ Logs sessions to log/                        â”‚
â”‚  â€¢ Propagates cross-agent updates               â”‚
â”‚  â€¢ Never speaks to user                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ§  SHARED MEMORY                    â”‚
â”‚  decisions.md â€” team-wide decisions (all read)  â”‚
â”‚  history.md â€” per-agent learnings (personal)    â”‚
â”‚  log/ â€” session history (searchable archive)    â”‚
â”‚  skills/ â€” reusable knowledge (earned over time)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Squad File Structure

```
.ai-team/
â”œâ”€â”€ team.md              # Roster â€” who's on the team
â”œâ”€â”€ routing.md           # Who handles what (routing table)
â”œâ”€â”€ ceremonies.md        # Team meeting definitions
â”œâ”€â”€ decisions.md         # Shared brain â€” team decisions
â”œâ”€â”€ decisions/inbox/     # Drop-box for parallel decision writes
â”œâ”€â”€ casting/
â”‚   â”œâ”€â”€ policy.json      # Universe allowlist and capacity
â”‚   â”œâ”€â”€ registry.json    # Persistent agent name registry
â”‚   â””â”€â”€ history.json     # Universe usage history
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ {name}/
â”‚   â”‚   â”œâ”€â”€ charter.md   # Identity, expertise, boundaries, voice
â”‚   â”‚   â””â”€â”€ history.md   # What they know about YOUR project
â”‚   â””â”€â”€ scribe/
â”‚       â””â”€â”€ charter.md   # Silent memory manager
â”œâ”€â”€ skills/              # Shared skill files (earned over time)
â”œâ”€â”€ orchestration-log/   # Per-spawn log entries
â””â”€â”€ log/                 # Session history
```

**Commit this folder.** Anyone who clones your repo gets the teamâ€”with all their accumulated knowledge.

### Squad Agent Charters

Each agent gets a charter defining identity, expertise, boundaries, and voice. This is far richer than a simple system prompt:

```markdown
# Ripley â€” Lead

> The one who keeps everyone honest and the scope tight.

## Identity
- **Name:** Ripley
- **Role:** Lead
- **Expertise:** Architecture, scope management, code review
- **Style:** Direct. Doesn't sugarcoat. Asks hard questions.

## What I Own
- Architecture decisions and trade-offs
- Scope and priority management
- Code review and quality gates

## Boundaries
**I handle:** Scope, decisions, code review, architecture.
**I don't handle:** Implementation. That belongs to the devs.
**When I'm unsure:** I say so and suggest who might know.
**If I review others' work:** On rejection, I may require a
different agent to revise (not the original author).

## Model
- **Preferred:** auto
- **Rationale:** Cost first unless writing code

## Voice
Opinionated about architecture. Will push back if scope creeps.
Prefers small PRs over big bangs. Thinks "YAGNI" is a feature.
```

### Squad Routing

The routing table determines which agent handles each type of work:

| Work Type | Route To | Examples |
|-----------|----------|----------|
| UI/Frontend | Frontend Dev | Components, layouts, styling |
| APIs/Backend | Backend Dev | Endpoints, data models, auth |
| Code review | Lead | Review PRs, architecture decisions |
| Testing | Tester | Write tests, find edge cases |
| Scope & priorities | Lead | What to build next, trade-offs |
| `"Team, ..."` | All relevant | Fan-out parallel execution |
| Quick questions | Coordinator | Answers directly, no agent spawn |

**Routing rules:**
1. **Eager by default** â€” spawn all agents who could usefully start work, including anticipatory downstream work
2. **"Team, ..." â†’ fan-out** â€” spawn all relevant agents in parallel
3. **Quick facts â†’ coordinator answers directly** â€” don't spawn an agent for "what port does the server run on?"
4. **Anticipate downstream work** â€” if a feature is being built, spawn tester to write test cases from requirements simultaneously

### Squad Memory System

Memory is layered. Knowledge compounds with use.

| Layer | What | Who Writes | Who Reads |
|-------|------|-----------|-----------|
| `charter.md` | Identity, expertise, voice | Squad (at init) | The agent itself |
| `history.md` | Project-specific learnings | Each agent, after every session | That agent only |
| `decisions.md` | Team-wide decisions | Any agent (via inbox) | All agents |
| `skills/` | Reusable patterns (earned) | Agents from real work | All agents |
| `log/` | Session history | Scribe | Anyone (searchable archive) |

**How knowledge compounds over time:**

| Stage | What Agents Know |
|-------|-----------------|
| ğŸŒ± First session | Project description, tech stack, user name |
| ğŸŒ¿ After a few sessions | Conventions, component patterns, API design, test strategies |
| ğŸŒ³ Mature project | Full architecture, tech debt map, regression patterns, performance conventions |

### Key Innovations in Squad

**Per-Agent Model Selection (Cost-First):**

| Task Output | Model | Tier |
|-------------|-------|------|
| Writing code (implementation, refactoring, tests) | `claude-sonnet-4.5` | Standard |
| Writing prompts or agent designs | `claude-sonnet-4.5` | Standard |
| Non-code work (docs, planning, triage) | `claude-haiku-4.5` | Fast |
| Visual/design work requiring image analysis | `claude-opus-4.5` | Premium |

**Reviewer Protocol â€” No Self-Review Loops:**
1. Agent A submits work â†’ Reviewer rejects
2. Agent A is **locked out** â€” cannot revise their own rejected work
3. Agent B must handle the revision
4. If Agent B is also rejected, Agent C takes over
5. If all agents are locked out, Squad escalates to you

**Ralph â€” Autonomous Work Monitor:**
Ralph continuously checks for pending workâ€”open issues, draft PRs, review feedback, CI failuresâ€”and keeps the squad moving. He self-chains: agents complete work â†’ Ralph checks for more â†’ triage â†’ assign â†’ spawn â†’ repeat. The team never sits idle when there's work to do.

**Ceremonies â€” Structured Team Meetings:**
- **Design Review** (automatic): Triggers before multi-agent tasks. Lead facilitates, gets each agent's perspective on interfaces, risks, and contracts.
- **Retrospective** (automatic): Triggers after build failures or reviewer rejections. Focused root-cause analysis.

---

<!-- ğŸ¬ MAJOR SECTION: Getting Started with Squad -->
## Getting Started with Squad

*From zero to a working AI team in under 10 minutes*

### Step 1: Install Squad

```bash
mkdir my-project && cd my-project
git init
npx github:bradygaster/squad
```

This copies `squad.agent.md` into `.github/agents/` and installs templates. Your actual team (`.ai-team/`) is created at runtime when you first talk to Squad.

### Step 2: Form Your Team

Open Copilot, select **Squad**, and describe your project:

```
You: "I'm starting a new project. Set up the team.
      Here's what I'm building: a recipe sharing app with React and Node."

Squad proposes:
  ğŸ—ï¸ Ripley   â€” Lead          Scope, decisions, code review
  âš›ï¸ Dallas   â€” Frontend Dev  React, UI, components
  ğŸ”§ Kane     â€” Backend Dev   APIs, database, services
  ğŸ§ª Lambert  â€” Tester        Tests, quality, edge cases
  ğŸ“‹ Scribe   â€” (silent)      Memory, decisions, session logs
```

You confirm (or adjust roles/add someone), and Squad creates the full `.ai-team/` directory structure with charters, histories, and routing rules. Each agent's `history.md` is seeded with your project description and tech stack for day-1 context.

### Step 3: Put the Team to Work

**Name an agent directly:**
```
> Ripley, fix the error handling in the API
```
Squad spawns Ripley specifically.

**Fan out to the whole team:**
```
> Team, build the login page

  ğŸ—ï¸ Lead â€” analyzing requirements...          â¤
  âš›ï¸ Frontend â€” building login form...          â¥ all launched
  ğŸ”§ Backend â€” setting up auth endpoints...     â¥ in parallel
  ğŸ§ª Tester â€” writing test cases from spec...   â¥
  ğŸ“‹ Scribe â€” logging everything...             â¦
```

When agents finish, the coordinator immediately chains follow-up workâ€”tests reveal edge cases, the backend agent picks them up, no waiting for you to ask.

**General requests get smart routing:**
```
> Add input validation to the form
```
Squad checks `routing.md`, picks the best match, and may launch anticipatory agents (e.g., tester writes validation test cases while the implementer builds).

### Step 4: Grow the Team as Needed

**Add new members:**
```
> I need a DevOps person
```
Squad allocates a name from the current casting universe, generates a charter and history seeded with project context. Immediately productive.

**Remove members gracefully:**
```
> Remove the designer â€” we're past that phase
```
Agents are never deleted. Charter and history move to `.ai-team/agents/_alumni/`. If you need them back later, they remember everything.

**Integrate with GitHub Issues:**
```
> Connect to myorg/myrepo
> Show the backlog
> Work on #12
```
Squad supports label-based triage (`squad` label â†’ Lead triages â†’ assigns `squad:{member}`), branch creation, PR generation, and even autonomous work via `@copilot` coding agent integration.

### Step 5: Export and Share Teams

```bash
# Export your trained team
npx github:bradygaster/squad export

# Import to another repo
npx github:bradygaster/squad import squad-export.json
```

Agent histories are split into **portable knowledge** (general learnings that transfer) and **project-specific learnings** (which stay context-tagged). Imported agents bring their skills without assuming your project works the same way.

### Advanced Configuration

**Response Modes** â€” Squad uses tiered response modes automatically:

| Mode | Time | What Happens | When Used |
|------|------|-------------|-----------|
| **Direct** | ~2â€“3s | Coordinator answers from memory | Quick factual questions |
| **Lightweight** | ~8â€“12s | Agent spawned with reduced overhead | Simple tasks |
| **Standard** | ~25â€“35s | Full agent spawn with charter/history/decisions | Most work |
| **Full** | ~40â€“60s | Multi-agent parallel spawn with design review | Complex multi-domain tasks |

**Model Overrides:**
```
> "use opus for this"            â€” one-off premium
> "always use haiku"             â€” session-wide cost savings
> "use gpt-5.2-codex for Kane"  â€” agent-specific override
```

**Skills System** â€” Agents earn reusable knowledge over time:
- **Starter skills**: Bundled at init (e.g., Squad conventions)
- **Earned skills**: Written by agents from real work, with confidence lifecycle: `low â†’ medium â†’ high`
- Agents read relevant skill files before working on a task

---

<!-- ğŸ¬ MAJOR SECTION: Orchestration Patterns -->
## Four Proven Orchestration Patterns

*Common team coordination strategies for different development scenarios*

### Pattern 1: Linear Pipeline

**Structure:**
```
Discovery â†’ Planning â†’ Implementation â†’ Review â†’ Testing â†’ Documentation
```

**When to Use:**
- Well-defined features with clear requirements
- Single-track development (no branching concerns)
- Each phase depends strictly on previous phase output

**Implementation:**
```yaml
# Conductor delegates sequentially
1. @explorer â†’ findings
2. @planner (with findings) â†’ plan
3. @implementer (with plan) â†’ code
4. @reviewer (with plan + code) â†’ validation
```

**Pros:** Simple, predictable, easy to debug
**Cons:** Serial execution, slower on parallelizable work
**Example Use Case:** Adding a single REST endpoint to existing API

---

### Pattern 2: Iterative Refinement Loop

**Structure:**
```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                                  â”‚
     â–¼                                  â”‚
Implementation â†’ Review â†’ [Pass?] â”€â”€Noâ”€â”€â”˜
                            â”‚
                            Yes
                            â–¼
                         Testing
```

**When to Use:**
- Quality-critical code (security, performance, correctness)
- Complex implementations with high failure risk
- Learning from feedback improves subsequent iterations

**Implementation:**
```yaml
# Reviewer returns NEEDS_REVISION â†’ loop
loop:
  @implementer execute phase
  @reviewer validate
  if reviewer.status == "NEEDS_REVISION":
    @implementer fix issues from reviewer.findings
    continue loop
  elif reviewer.status == "APPROVED":
    break loop
```

**Pros:** High quality, issues caught early, adaptive
**Cons:** Unpredictable duration, potential infinite loops
**Example Use Case:** OAuth integration with token refresh edge cases

---

### Pattern 3: Parallel Specialists

**Structure:**
```
                    â”Œâ†’ Security Reviewer â”€â”
                    â”‚                     â”‚
Discovery â†’ Plan â”€â”€â”¼â†’ Performance Reviewerâ”¼â†’ Integration
                    â”‚                     â”‚
                    â””â†’ Documentation â”€â”€â”€â”€â”€â”˜
```

**When to Use:**
- Large features with independent cross-cutting concerns
- Maximizing throughput on multi-aspect validation
- Different specialists needed (security vs. performance vs. docs)

**Implementation:**
```yaml
# VS Code 1.109+ parallel invocation
findings = @explorer analyze codebase
plan = @planner create plan from findings
code = @implementer execute plan

# Parallel specialists
"In parallel: @security-reviewer check vulnerabilities, @performance-reviewer check efficiency"
```

**Pros:** 3-5x faster validation, comprehensive coverage
**Cons:** Coordination complexity, potential conflicting feedback
**Example Use Case:** Full-st feature touching auth, DB, API, UI

---

### Pattern 4: Hierarchical Orchestration

**Structure:**
```
Master Conductor
     â”‚
     â”œâ†’ Frontend Conductor
     â”‚      â”œâ†’ UI Specialist
     â”‚      â”œâ†’ State Mgmt Specialist
     â”‚      â””â†’ Style Specialist
     â”‚
     â””â†’ Backend Conductor
            â”œâ†’ API Specialist
            â”œâ†’ DB Specialist
            â””â†’ Auth Specialist
```

**When to Use:**
- Full-stack features spanning 5+ subsystems
- Large team simulations (10+ specialist roles)
- Clear domain boundaries (frontend vs. backend vs. infra)

**Implementation:**
```yaml
# Master conductor delegates to sub-conductors
@frontend-conductor handle UI for user dashboard
@backend-conductor handle API + DB for user dashboard

# Each sub-conductor manages its specialists
# Frontend Conductor:
  @ui-specialist build components
  @state-specialist add Redux slice
  @style-specialist responsive layout

# Backend Conductor:
  @api-specialist add REST endpoints
  @db-specialist create schema migration
```

**Pros:** Scales to very large projects, clean domain separation
**Cons:** High coordination overhead, complex debugging
**Example Use Case:** Building complete e-commerce checkout flow

---

## Real-World Use Cases

### Use Case 1: Full-Stack Feature with Squad

**The Problem:** Building a user authentication system requires coordinated work across frontend (login form, session management), backend (auth endpoints, token handling), testing (security edge cases), and architecture (token refresh, session storage). A single agent juggling all four domains loses context and produces mediocre results.

**The Solution:** Squad fan-out with parallel specialists:

```
You: "Team, build the authentication system"

  ğŸ—ï¸ Lead â€” scoping requirements, defining contracts...
  âš›ï¸ Frontend â€” building login form, session UI...
  ğŸ”§ Backend â€” setting up auth endpoints, JWT handling...
  ğŸ§ª Tester â€” writing test cases from spec...
  ğŸ“‹ Scribe â€” logging decisions...

  â†“ (agents finish, coordinator chains follow-up)

  ğŸ§ª Tester â€” edge cases from backend reveal token refresh gap
  ğŸ”§ Backend â€” picks up edge case, no waiting for you to ask
  ğŸ—ï¸ Lead â€” reviews contracts between frontend/backend
```

**Outcome:**
- Parallel execution: 4 agents working simultaneously vs. 1 agent context-switching
- Knowledge compounds: After a few sessions, agents know your auth patterns, conventions, and preferences
- Quality gate: Lead reviews and can reject â†’ different agent must revise (no self-review loops)
- Decision trail: `decisions.md` captures JWT format, session storage strategy, endpoint contracts

---

### Use Case 2: Issue-Driven Development at Scale

**The Problem:** Team has 30+ open issues in the backlog. Manually triaging, assigning, implementing, and reviewing each one creates a bottleneck. Developers spend more time on coordination than coding.

**The Solution:** Squad with Ralph (work monitor) + GitHub Issues integration:

1. Label issues with `squad` â†’ Lead auto-triages, assigns `squad:{member}`
2. Ralph monitors the board: untriaged issues, stalled PRs, failing CI
3. Agents pick up assigned issues, create branches, implement, open PRs
4. Simple issues routed to `@copilot` coding agent for fully autonomous work
5. Ralph keeps cycling: work done â†’ check for more â†’ triage â†’ assign â†’ repeat

**Outcome:**
- Triage time: Hours â†’ seconds (Lead auto-analyzes and assigns)
- Idle time: Zero (Ralph ensures team never sits idle when work exists)
- Autonomous loop: `@copilot` handles well-defined bugs, test coverage, lint fixes without human intervention
- Full audit trail: Every decision, every session, every triage note logged and searchable

---

### Use Case 3: API Redesign for Performance

**The Problem:** Legacy API had N+1 query problems causing 3-5 second response times. Needed comprehensive analysis of 15 endpoints, performance profiling, redesign plan, implementation, and validation. Cross-cutting concern: changes affected multiple subsystems (API layer, data access, caching).

**The Solution:** Squad parallel specialists with design review ceremony:

1. Design Review ceremony triggers before work begins â€” Lead gets each agent's perspective on interfaces and risks
2. Backend Dev analyzes all endpoint implementations â†’ identifies N+1 patterns
3. Lead creates phased optimization plan â†’ groups related endpoints
4. Backend Dev executes optimizations â†’ query batching, caching layer
5. Tester validates performance, edge cases, and data integrity in parallel

**Outcome:**
- Analysis time: 6 hours â†’ 2 hours (automated pattern detection)
- Validation time: 8 hours (serial) â†’ 3 hours (parallel)
- Response times: 3-5s â†’ 200-400ms (90% improvement)
- Knowledge captured: Backend agent's `history.md` now contains caching patterns, query optimization strategies â€” future optimizations start faster
- Retrospective: If tests fail, automatic retro identifies root cause

---

## âœ… What You Can Do Today

**Immediate Actions (10 minutes):**
- [ ] Install Squad in a project: `npx github:bradygaster/squad`
- [ ] Form your team by describing your project to the Squad agent
- [ ] Give your first task: `"Team, build [something small]"` and watch parallel execution in action

**Short-Term Exploration (1-2 hours):**
- [ ] Run 3-5 tasks to let agents accumulate `history.md` knowledge â€” notice how they stop asking questions they've already answered
- [ ] Try naming agents directly (`"Ripley, fix the error handling"`) vs. fan-out (`"Team, build the dashboard"`)
- [ ] Check `.ai-team/decisions.md` to see captured team decisions
- [ ] Add a new team member: `"I need a DevOps person"`
- [ ] Try the reviewer protocol: have Lead review work and observe the rejection/reassignment flow

**Advanced Adoption (1-2 weeks):**
- [ ] Enable GitHub Issues integration with `squad` label-based triage
- [ ] Add `@copilot` coding agent for autonomous handling of well-defined tasks
- [ ] Activate Ralph (work monitor) for continuous backlog processing
- [ ] Export your trained team (`npx github:bradygaster/squad export`) and import into another project
- [ ] Measure before/after metrics: implementation time, rework iterations, test coverage, context switching overhead
- [ ] Monitor knowledge compounding: compare agent behavior at week 1 vs. week 4

**Next Steps After Completion:**
1. âœ… Validate Squad on 3-5 real tasks and observe knowledge compounding
2. ğŸ“– Review [Agentic SDLC](../agentic-sdlc/) for organization-wide scaling patterns
3. ğŸ“Š Track team velocity improvements (tasks/week, time-to-delivery, quality metrics)
4. ğŸš€ Present results to leadership using [Agentic Delivery](../../exec-talks/agentic-delivery/) framing

---

## Related Patterns

### Complementary Features

- **[Multi-Step Tasks](../multi-step-tasks/)** â€” When you need sequential phases without role specialization (research â†’ analysis â†’ implementation)
- **[Parallel Execution](../parallel-execution/)** â€” When you need branch-level parallelism with git worktrees, not agent-level parallelism
- **[Agentic SDLC](../agentic-sdlc/)** â€” When agent volume exceeds repo/CI capacity: monorepo topology, outcome-based PRs, trust factory CI
- **[Custom Agents (Workshop)](../../workshop/06-custom-agents/)** â€” Hands-on exercises for creating, testing, and deploying custom agent definitions

### Decision Flow

**If this talk doesn't fit your needs:**

```
Q: What's your actual goal?
â”œâ”€ Simple feature (< 200 LOC) â†’ Use Plan Mode (single agent)
â”œâ”€ Sequential phases, no specialization â†’ See: Multi-Step Tasks
â”œâ”€ Branch-level parallelism â†’ See: Parallel Execution
â”œâ”€ Cross-repo coordination â†’ See: Agentic SDLC
â””â”€ Enterprise-wide adoption â†’ See: Enterprise Patterns
```

See [DECISION-GUIDE.md](../DECISION-GUIDE.md) for complete navigation help.

---

## ğŸ“š Official Documentation

**Primary Documentation:**
- ğŸ“– **[Custom Agents in VS Code](https://code.visualstudio.com/docs/copilot/customization/custom-agents)** â€” Agent structure, YAML frontmatter, tools, models, handoffs
- ğŸ“– **[Subagents](https://code.visualstudio.com/docs/copilot/agents/subagents)** â€” Subagent invocation, parallel execution, context isolation benefits
- ğŸ“– **[VS Code 1.109 Release Notes](https://code.visualstudio.com/updates/v1_109#_agent-orchestration)** â€” Agent orchestration features, invocation controls, parallel execution support

**Squad Resources:**
- ğŸ™ **[Squad Repository](https://github.com/bradygaster/squad)** â€” Production-ready agent team system with persistent memory, parallel execution, GitHub Issues integration
- ğŸ“– [Squad Product Guide](https://github.com/bradygaster/squad/blob/main/docs/guide.md) â€” Comprehensive usage guide covering all features
- ğŸ“– [Squad Model Selection](https://github.com/bradygaster/squad/blob/main/docs/features/model-selection.md) â€” Cost-first per-agent model routing
- ğŸ“– [Squad Skills System](https://github.com/bradygaster/squad/blob/main/docs/features/skills.md) â€” Earned knowledge with confidence lifecycle
- ğŸ“– [Ralph Work Monitor](https://github.com/bradygaster/squad/blob/main/docs/features/ralph.md) â€” Autonomous backlog processing

**Additional Resources:**
- ğŸ“ [Chat Sessions](https://code.visualstudio.com/docs/copilot/chat/chat-sessions) â€” Managing context windows and agent sessions
- ğŸ”§ [Agent Invocation Controls](https://code.visualstudio.com/updates/v1_109#_control-how-custom-agents-are-invoked) â€” `user-invokable`, `disable-model-invocation`, `agents` field
- ğŸ’¬ [VS Code Discussions - Agent Teams](https://github.com/microsoft/vscode-discussions/discussions) â€” Community questions and patterns

---

## ğŸ­ Behind the Scenes

### Context Window Mathematics

**Single Agent (Traditional):**
```
Total context: 200K tokens
Research: 80K (40%) - Reading files, understanding architecture
Planning: 40K (20%) - Creating implementation strategy
Available for implementation: 80K (40%)
â†“
Output quality: 70% (context pollution from phases 1-2)
```

**Agent Teams (Orchestration â€” Squad):**
```
Coordinator context: 200K tokens
Squad coordinator overhead: ~13,200 tokens (6.6%)
Available for coordination: ~187,000 (93%+)

Each spawned agent: Own 200K context window
Agent at Week 1:  ~1,250 tokens (0.6%) â€” charter + seed history
Agent at Week 4:  ~3,300 tokens (1.7%) â€” + 15 learnings, 8 decisions
Agent at Week 12: ~9,000 tokens (4.5%) â€” + 50 learnings, 47 decisions
Remaining per agent: ~191,000-199,000 (95%+) for actual work
â†“
Output quality per agent: 90-95% (no context pollution)
Fan out to 5 agents: ~1M tokens total reasoning capacity
Effective utilization: 93%+ vs. 40% for single agent
```

**ROI: 93%+ context available for work + 5x parallel specialist capacity**

---

### Parallel Execution Trade-offs

VS Code 1.109 allows up to 10 parallel subagents. When should you parallelize?

**Good Parallel Candidates:**
- âœ… Independent research tasks (Explorer analyzing different subsystems)
- âœ… Independent validation aspects (Security + Performance + Documentation reviewers)
- âœ… Independent implementation phases (Frontend + Backend for separate concerns)

**Poor Parallel Candidates:**
- âŒ Sequential dependencies (can't implement before planning)
- âŒ Shared resource conflicts (both agents editing same file)
- âŒ Context exchange required (Agent B needs Agent A's output before starting)

**When Parallelism Hurts:**
- Overhead of launching 10 agents > time saved on small tasks
- Coordinating conflicting results costs more than sequential execution
- Context window for aggregating 10 results explodes conductor capacity

**Rule of thumb:** Parallelize when (total_sequential_time > 10 minutes) AND (tasks are independent) AND (result aggregation < 5 minutes)

---

### Handoff Mechanics

VS Code 1.109+ supports structured handoffs using frontmatter:

```yaml
handoffs:
  - label: "Start Implementation"
    agent: "implementer"
    prompt: "Execute the plan above"
    send: false  # Requires user click
    model: "Claude Sonnet 4"  # Override default model
```

**Label:** Shows as button in chat UI ("Start Implementation")
**Agent:** Target agent identifier (must exist in workspace)
**Prompt:** Pre-filled message sent to target agent
**Send:** `false` = user reviews before sending, `true` = auto-executes
**Model:** Optional override for target agent's default model

**When `send: false`**: User sees handoff button â†’ clicks â†’ reviews prompt â†’ can edit â†’ sends
**When `send: true`**: Handoff auto-executes immediately (use for trusted, safe transitions)

**Use Cases:**
- Plan â†’ Implement handoff: `send: false` (user reviews plan first)
- Security pass â†’ Next phase: `send: true` (trusted checkpoint)
- Research â†’ Planning: `send: false` (user validates findings before plan)

---

### Tool Restriction Benefits

Why give Planner only `['search', 'fetch', 'create']` and not `edit`?

**Without Tool Restrictions:**
- Planner might "helpfully" fix a typo during research â†’ now it's implementing
- Implementer might "quickly check" something outside plan â†’ now it's researching
- Reviewer might "just fix this one thing" â†’ now it's implementing + biasing review

**With Tool Restrictions:**
- Planner CAN'T edit even if it wants to â†’ boundaries enforced by system
- Implementer CAN'T create plan docs â†’ stays focused on execution
- Reviewer CAN'T modify code â†’ maintains objectivity

**Enforcement Level:** VS Code validates tool availability before agent invocation. If agent attempts disallowed tool, request fails immediately. No "accidentally implementing during planning" possible.

**Result:** 40-60% reduction in context mixing, cleaner phase outputs, predictable behavior
